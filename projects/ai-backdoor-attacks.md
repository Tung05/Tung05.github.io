---
date: 2025-05-12
layout: page
tags: [ai, cybersecurity, research]
---

[‚Üê Back to Projects](/projects/)

{% if page.tags %}
**Tags:** {{ page.tags | join: ", " }}
{% endif %}

# Backdoor Attacks in AI Models - Research Paper

**Summary:** Researched vulnerabilities in ML models, identifying backdoor attacks and mitigation strategies.

**Full Paper**
üìÑ [Download Full Paper (PDF)](../images/Backdoor%20in%20AI.pdf)

---

## Objective
Investigate how malicious actors can inject backdoors into AI/ML models and propose defenses for critical applications such as automotive and healthcare.

---

## Key Findings
- Analyzed attack methods: Trojan Attacks, BadNets, and data poisoning.  
- Proposed mitigation strategies: dataset vetting, adversarial retraining, and neural activation clustering.  
- Explored detection techniques for model integrity and security.

---

## Tools & Techniques
Python, TensorFlow, ML model analysis, gradient inspection, neural activation clustering
